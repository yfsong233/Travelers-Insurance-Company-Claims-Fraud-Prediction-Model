---
title: "Statathon try-out"
author: "Yufeng Song"
output: github_document
---

You work for Travelers Insurance Company's fraud detection department as a modeler. Create a predictive model with concerns about the fraud detection accuracy AND the key drivers that cause fraudulence.

Goals: 
(1) identify first-party physical damage fraudulence 
(2) explain the indicators of fraudulent claims.

```{r preprocessing}
library(tidyverse)
library(vcd)
library(lubridate)
library(zipcodeR)

train <- read.csv("data copy/train_2023.csv")

train %>% head(10)

## fill missing values
train <- train[complete.cases(train), ]
#train_missing <- train %>% select_if(~ any(is.na(.))) %>% filter_if(~ any(is.na(.)), all_vars(!is.na(.)))
# "marital_status"      "witness_present_ind" "claim_est_payout"    "age_of_vehicle"

## outliers
# age_of_driver

## transformation


```

```{r univariate visualization}
if (!is.factor(train$fraud)) {
  train$fraud <- as.factor(train$fraud)
  train$fraud <- factor(train$fraud, levels = c(0, 1), labels = c("No Fraud", "Fraud"))
}

# 1. fraud against age - Done
train %>%
  mutate(age_group = cut(age_of_driver, breaks = seq(0, 100, 10), 
                         include.lowest = TRUE)) %>%
  ggplot(aes(age_group, fill = fraud)) +
  geom_histogram(position = "fill", stat="count") +
  scale_x_discrete(labels = c("0-10", "11-20", "21-30", "31-40", "41-50", "51-60", "61-70", "71-80", "81-90", "91-100")) +
  scale_fill_discrete(name="Fraud")

# 2. fraud against gender - Done

train %>% ggplot(aes(gender, fill = factor(fraud))) +
  geom_bar(position = "fill") +
  scale_fill_discrete(name = "Fraud")

# 3. fraud against marital_status - Done
## labels=c("No", "Yes")
train %>% 
  filter(!is.na(marital_status)) %>%
  ggplot(aes(x = factor(marital_status), fill = factor(fraud))) + 
  geom_bar(position = "fill")+
  scale_fill_discrete(name="Fraud")

# 4. fraud against safety rating - Done
train %>% ggplot(aes(safty_rating, factor(fraud))) + 
  geom_boxplot(na.rm=T) + coord_flip()

# 5. fraud against annual income - Done
train %>%
  filter(!is.na(annual_income), annual_income >= 20000) %>% 
  ggplot(aes(factor(fraud),annual_income)) + 
  geom_violin()

# 6. fraud against high_education_ind - Done
train %>% 
  filter(!is.na(high_education_ind)) %>%
  ggplot(aes(x = factor(high_education_ind), fill = factor(fraud))) + 
  geom_bar(position = "fill")

# 7. fraud against address_change_ind - Done
train %>% 
  filter(!is.na(address_change_ind)) %>%
  ggplot(aes(x = factor(address_change_ind), fill = factor(fraud))) + 
  geom_bar(position = "fill")

# 8. fraud against living_status - Done
mosaicplot(~ living_status + fraud, 
           data = train, 
           color = c("lightgreen", "lightblue"), 
           main = "Relationship between Living Status and Fraud")

  # bar graph attempt
train %>% ggplot(aes(living_status, fill = factor(fraud))) +
  geom_bar(position = "dodge")

## 9. fraud against zip_code - DONE
train_no_na_zip <- train %>%
  mutate(zip_code = as.character(zip_code)) %>% 
  filter(zip_code %in% zip_code_db$zipcode) %>% 
  left_join(zip_code_db, by = c("zip_code" = "zipcode")) %>%
  select(zip_code, fraud, state)

train_no_na_zip <- train_no_na_zip %>%
  mutate(fraud_ind = as.numeric(fraud)) %>%
  group_by(state) %>%
  summarize(num_fraud = sum(fraud_ind),
            total = n(),
            prop_fraud = num_fraud / total) %>%
  ungroup()

  # frequency plot attempt
train_no_na_zip %>% 
  ggplot(aes(state, prop_fraud, fill = prop_fraud)) +
  geom_bar(stat = "identity")

  # heatmap attempt
train_no_na_zip %>%
  mutate(state_fct = as.factor(state)) %>%
  complete(state_fct = factor(state_fct, levels = unique(state_fct))) %>% 
  ggplot(aes(state, state, fill = prop_fraud)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red")

  # scatter plot attempt
train_no_na_zip %>%
  ggplot(aes(state, prop_fraud)) +
  geom_point()

  # line plot attempt
train_no_na_zip %>%
  ggplot(aes(state, prop_fraud, group = 1)) +
  geom_line(color = "blue") +
  geom_point()


## 10. fraud against claim_date - Done
train$month <- month(parse_date_time(train$claim_date, "mdy"))
train$season <- factor(case_when(train$month %in% 3:5 ~ "Spring",
                              train$month %in% 6:8 ~ "Summer",
                              train$month %in% 9:11 ~ "Fall",
                              TRUE ~ "Winter"))
train$claim_date <- as.Date(parse_date_time(train$claim_date, "mdy"))

aggr_train <- train %>%
  group_by(season, fraud) %>%
  summarize(count = n()) %>%
  mutate(total = sum(count),
         rate = count/sum(count))

aggr_train %>% ggplot(aes(season, rate, color = factor(fraud))) +
  geom_line() +
  scale_color_discrete(name = "Fraud")

aggr_train %>% ggplot(aes(season, rate, color = factor(fraud))) +
  geom_point(alpha = 0.5) +
  geom_line(aes(group = fraud), position = position_dodge(width = 0.2)) +
  scale_x_discrete(limits = c("Spring", "Summer", "Fall", "Winter"))
  scale_color_discrete(name = "Fraud")


  # boxplot attempt
train %>% ggplot(aes(season, fraud)) + 
  geom_boxplot()

  # frequency plot attempt
train %>%
  ggplot() + 
  geom_bar(aes(season, fill = fraud), position = "dodge") +
  scale_fill_discrete(name = "Fraud")

## 11. fraud against claim_day_of_week - Done
train %>% ggplot(aes(claim_day_of_week, fill=factor(fraud))) +
  geom_bar(position="fill")

## 12. fraud against accident_site - Done
train %>% ggplot(aes(accident_site, fill=factor(fraud))) +
  geom_bar(position="fill")

## 13. fraud against past_num_of_claims - Done
train %>% ggplot(aes(past_num_of_claims, factor(fraud))) +
  geom_count()

  # boxplot attempt
train %>% 
  filter(!is.na(past_num_of_claims) & past_num_of_claims > 0) %>% 
  ggplot(aes(fraud, log(past_num_of_claims), fill = fraud)) +
  geom_boxplot()

## 14. fraud against witness_present_ind - Done
train %>% 
  filter(!is.na(witness_present_ind)) %>%
  ggplot(aes(x = factor(witness_present_ind), fill = factor(fraud))) + 
  geom_bar(position = "fill")

## 15. fraud against liab_prct - Done
train %>% ggplot(aes(liab_prct, fill = factor(fraud))) +
  geom_density(alpha = 0.5)

## 16. fraud against channel - Done
train %>% 
  filter(!is.na(channel)) %>%
  ggplot(aes(x = factor(channel), fill = factor(fraud))) + 
  geom_bar(position = "fill")
  
## 17. fraud against policy_report_filed_ind
train %>% 
  filter(!is.na(policy_report_filed_ind)) %>%
  ggplot(aes(x = factor(policy_report_filed_ind), fill = factor(fraud))) + 
  geom_bar(position = "fill")

## 18. fraud against claim_est_payout
train %>% 
  ggplot(aes(fraud, claim_est_payout, fill = fraud)) + 
  geom_boxplot() +
  scale_fill_discrete(name="Fraud")

## 19. fraud against age_of_vehicle
train %>%
  ggplot(aes(factor(age_of_vehicle), fill = factor(fraud))) +
  geom_bar(position = "dodge") +
  scale_fill_discrete(name="Fraud")

  # box plot attempt
train %>% 
  ggplot(aes(factor(fraud), age_of_vehicle, fill = fraud)) +
  geom_boxplot(position = "dodge")

## 20. fraud against vehicle_category
train %>% 
  filter(!is.na(vehicle_category)) %>%
  ggplot(aes(x = factor(vehicle_category), fill = factor(fraud))) + 
  geom_bar(position = "fill")

## 21. fraud against LOG TRANSFORMED vehicle_price
train %>% 
  ggplot(aes(log(vehicle_price), fill = factor(fraud))) +
  geom_density(alpha = 0.5)

## 22. fraud against vehicle_color
train %>% 
  filter(!is.na(vehicle_color)) %>%
  ggplot(aes(x = factor(vehicle_color), fill = factor(fraud))) + 
  geom_bar(position = "fill")

## 23. fraud against vehicle_weight
train %>% 
  ggplot(aes(factor(fraud), vehicle_weight, fill = factor(fraud))) + 
  geom_boxplot(alpha = 0.5) +
  scale_fill_discrete(name="Fraud")
```
```{r hypothesis tests}
# 1. fraud against age-NOT DONE
#H0: p1=...=p10=0 vs H1: pi != pj for at least one pair (i!=j).
## Chi_sq test for multiple proportions
age_uni
age_chi <- train %>%
  mutate(age_group = cut(age_of_driver, breaks = seq(0, 100, 10), include.lowest = TRUE)) %>% 
  filter(!is.na(age_group)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(age_group) %>%
  summarize(age_total = n(),
            age_fraud = sum(fraud_numeric == 1))
age_chi

age_prop_chi <-chisq.test(age_chi$age_fraud,age_chi$age_total)
age_prop_chi
###The warning message "Chi-squared approximation may be incorrect" is often caused by a small sample size or a low expected count in one or more cells of the contingency table.


###### try to use chisq.test as in #16.
##fisher_exact test
age_fisher <- train %>%
  mutate(age_group = cut(age_of_driver, breaks = seq(0, 100, 10), include.lowest = TRUE)) %>% 
  filter(!is.na(age_group)) %>%
  select(age_group, fraud) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(age_group) %>%
  summarize(age_fraud = sum(fraud_numeric==1),age_no_fraud= sum(fraud_numeric==0))

age_fisher

age_table <- as.table(as.matrix(age_fisher[, c("age_fraud", "age_no_fraud")]))
rownames(age_table) <- age_fisher$age_group
colnames(age_table) <- c("age_fraud", "age_no_fraud")
age_table

age_prop_fisher <- fisher.test(age_table,simulate.p.value=TRUE)
age_prop_fisher
###the size of your contingency table is too large for the FEXACT algorithm used by fisher.test(). Use the simulate.p.value=TRUE argument( Monte Carlo simulation to estimate the p-value instead of the FEXACT algorithm)
###p-value = 0.0004998,the age groups are no exactly the same.

# Perform pairwise comparison of proportions using Fisher's exact test
fisher_pairwise <- pairwise.prop.test(age_table, p.adjust.method = "bonferroni",pool.sd = FALSE)


# 2. fraud agasint gender
gender_uni
gender_z <- train %>%
  filter(!is.na(gender)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(gender) %>%
  summarize(gender_total = n(),
            gender_fraud = sum(fraud_numeric == 1))
gender_z

gender_prop_z <-prop.test(gender_z$gender_fraud,gender_z$gender_total,alternative="greater")
gender_prop_z
#p-value=8.974e-10 (< 0.05), we reject the null hypothesis and conclude that there is evidence to suggest that the proportion of fraud cases is greater for females than for males.

# 3. fraud against marital_status
ms_uni
ms_z <- train %>% 
  filter(!is.na(marital_status)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0),marital_status_text = ifelse(marital_status == 1, "Yes", "No"))%>%
  group_by(marital_status_text) %>%
  summarize(ms_total = n(),
            ms_fraud = sum(fraud_numeric == 1))
ms_z

ms_prop_z <-prop.test(ms_z$ms_fraud,ms_z$ms_total,alternative="greater")
ms_prop_z

#p-value < 2.2e-16 (< 0.05), we reject the null hypothesis and conclude that there is evidence to suggest that the proportion of fraud cases is greater for unmarried people than for married people.

# 4. fraud against safety ratings
##boxplot: sample distribution is skewed to the left
## reflection -> log transformation -> approximate normal ->lilliefors' test in KS, CvM, AD variations.

# Select and filter the fraud data
sr_fraud <- train %>% 
  select(fraud, safty_rating) %>%
  filter(!is.na(safty_rating), fraud == "Fraud")

# Select and filter the no-fraud data
sr_no_fraud <- train %>% 
  select(fraud, safty_rating) %>%
  filter(!is.na(safty_rating), fraud == "No Fraud")

library(twosamples)
cvm_test(sr_fraud$safty_rating, sr_no_fraud$safty_rating)

##The output suggests that the Cramer-von Mises test did not find any bootstrap values that were more extreme than the observed value. Therefore, the reported p-value is an imprecise placeholder, which means that the true p-value is lower than the reported value. This occurs because the Cramer-von Mises test uses bootstrapping to estimate the p-value, and sometimes the number of bootstrap samples is not sufficient to obtain a precise estimate of the p-value. In this case, increasing the number of bootstraps may help obtain a more precise estimate.


ad_test(sr_fraud$safty_rating, sr_no_fraud$safty_rating)

#The Anderson-Darling test statistic measures the discrepancy between the cumulative distribution functions of the two samples. A larger value of the test statistic indicates a greater difference between the two distributions. The p-value represents the probability of observing a test statistic as extreme as the one observed, assuming the null hypothesis of equal distributions is true. A small p-value (e.g., less than 0.05) suggests strong evidence against the null hypothesis, and indicates that the two samples come from different distributions. Conversely, a large p-value suggests weak evidence against the null hypothesis, and indicates that the two samples come from similar distributions.

## the results of two tests are so different, but it shows that the distributions of safty_ratings for fraud and no fraud are statistically significant.


# 5. fraud against annual income
income_uni <- train %>%
  filter(!is.na(annual_income), annual_income >= 20000) %>% 
  ggplot(aes(factor(fraud),annual_income)) + 
  geom_violin()

income_fraud <- train %>% 
  select(fraud, annual_income) %>%
  filter(!is.na(annual_income), fraud == "Fraud")

income_no_fraud <- train %>% 
  select(fraud, annual_income) %>%
  filter(!is.na(annual_income), fraud == "No Fraud")

cvm_test(income_fraud$annual_income, income_no_fraud$annual_income)

ad_test(income_fraud$annual_income, income_no_fraud$annual_income)

# the results of two tests are so different, but it shows that the distributions of annual_income for fraud and no fraud are statistically significant.

# 6. fraud against high_education_ind
edu_uni
edu_z <- train %>% 
  filter(!is.na(high_education_ind)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0), edu_text = ifelse(high_education_ind == 1, "Yes", "No"))%>%
  group_by(edu_text) %>%
  summarize(edu_total = n(),
            edu_fraud = sum(fraud_numeric == 1))
edu_z

edu_prop_z <-prop.test(edu_z$edu_fraud,edu_z$edu_total,alternative="greater")
edu_prop_z

#p-value < 2.2e-16 (< 0.05), we reject the null hypothesis and conclude that there is evidence to suggest that the proportion of fraud cases is greater for people received high education than for  people who didn't.

# 7. fraud against address_change_ind
address_uni

address_z <- train %>% 
  filter(!is.na(address_change_ind)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0), address_text = ifelse(address_change_ind == 1, "Yes", "No")) %>%
  group_by(address_text) %>%
  summarize(address_total = n(), address_fraud = sum(fraud_numeric == 1))
address_z

address_prop_z <-prop.test(address_z$address_fraud,address_z$address_total,alternative="less")
address_prop_z

#p-value < 2.2e-16 (< 0.05), we reject the null hypothesis and conclude that there is evidence to suggest that the proportion of fraud cases is greater for people changed address than people who didn't.

# 8. fraud against living_status
mosaicplot(~ living_status + fraud, 
           data = train, 
           color = c("lightgreen", "lightblue"), 
           main = "Relationship between Living Status and Fraud")

live_z <- train %>% 
  filter(!is.na(living_status)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(living_status) %>%
  summarize(live_total = n(), live_fraud = sum(fraud_numeric == 1))
live_z

live_prop_z <-prop.test(live_z$live_fraud,live_z$live_total,alternative="two.sided")
live_prop_z

#p-value =2.051e-05 (< 0.05), we reject the null hypothesis and conclude that there is evidence to suggest that the proportion of fraud cases for people rent a place is the differnt people who own a place.

# 9. fraud against zip_code - NOT DONE

# 10. fraud against claim_date - NOT DONE
train %>% ggplot(aes(season, fill = factor(fraud)))+
  geom_bar(position = "dodge") +
  scale_fill_manual(values = c("blue", "red"))

# 11. fraud against claim_day_of_week
week_uni
week_chi <- train %>%
  filter(!is.na(claim_day_of_week)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(claim_day_of_week) %>%
  summarize(week_total = n(),
            week_fraud = sum(fraud_numeric == 1))
week_chi

week_prop_chi <-prop.test(week_chi$week_fraud,week_chi$week_total,alternative="two.sided")
week_prop_chi

##p-value =0.1044 (> 0.05), we fail to reject the null hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for claim_day_of_week have no difference.

# 12. fraud against accident_site
site_uni
site_chi <- train %>%
  filter(!is.na(accident_site)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(accident_site) %>%
  summarize(site_total = n(),
            site_fraud = sum(fraud_numeric == 1))
site_chi

site_prop_chi <-prop.test(site_chi$site_fraud,site_chi$site_total, alternative="two.sided")
site_prop_chi
## p-value = 0.1037 (> 0.05), we fail to reject the null hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for accident_site have no difference.

# 13. fraud against past_num_of_claims-NOT DONE
past_uni
past_fraud <- train %>% 
  select(fraud, past_num_of_claims) %>%
  filter(!is.na(past_num_of_claims), fraud == "Fraud")
past_fraud

past_no_fraud <- train %>% 
  select(fraud, past_num_of_claims) %>%
  filter(!is.na(past_num_of_claims), fraud == "No Fraud")
past_no_fraud

cvm_test(past_fraud$past_num_of_claims, past_no_fraud$past_num_of_claims)
ad_test(past_fraud$past_num_of_claims, past_no_fraud$past_num_of_claims)

# The distributions of past_num_of_claims for fraud and no fraud are significant different.

# 14. fraud against witness_present_ind - Done
witness_uni
witness_z <- train %>%
  filter(!is.na(witness_present_ind)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0), witness_text = ifelse(witness_present_ind == 1, "Yes", "No")) %>%
  group_by(witness_present_ind) %>%
  summarize(witness_total = n(),
            witness_fraud = sum(fraud_numeric == 1))
witness_z

witness_prop_z <-prop.test(witness_z$witness_fraud,witness_z$witness_total,alternative="greater")
witness_prop_z

##p-value < 2.2e-1 (< 0.05), we reject the null hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for no witness present is higher than those with witness present.

## 15. fraud against liab_prct - Done
train %>% ggplot(aes(liab_prct, fill = factor(fraud))) +
  geom_density(alpha = 0.5)

liab_fraud <- train %>% 
  select(fraud, liab_prct) %>%
  filter(!is.na(liab_prct), fraud == "Fraud")

liab_fraud

liab_no_fraud <- train %>% 
  select(fraud, liab_prct) %>%
  filter(!is.na(liab_prct), fraud == "No Fraud")

liab_no_fraud

cvm_test(liab_fraud$liab_prct, liab_no_fraud$liab_prct)
ad_test(liab_fraud$liab_prct, liab_no_fraud$liab_prct)
## the distributions of liab_pct for fraud and no fraud are statistically significant.

## 16. fraud against channel
channel_uni
channel_chi <- train %>%
  filter(!is.na(channel)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(channel) %>%
  summarize(channel_total = n(),
            channel_fraud = sum(fraud_numeric == 1)) %>%
  select(channel_total, channel_fraud)

as.matrix(channel_chi)

channel_matrix <- as.matrix(channel_chi)
dim(channel_matrix)
channel_prop_chi <- chisq.test(channel_matrix)
channel_prop_chi
##p-value =0.4989 (> 0.05), we fail to reject the null hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for different channels have no difference.

# 17. fraud against policy_report_filed_ind
policy_uni
policy_z <- train %>%
  filter(!is.na(policy_report_filed_ind)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0), policy_text = ifelse(policy_report_filed_ind == 1, "Yes", "No")) %>%
  group_by(policy_text) %>%
  summarize(policy_total = n(),
            policy_fraud = sum(fraud_numeric == 1))
policy_z

policy_prop_z <-prop.test(policy_z$policy_fraud,policy_z$policy_total,alternative="less")
policy_prop_z

##p-value = 0.001284(< 0.05), we reject the null  hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for people did not file the report is less than those who filed the report.

# 18. fraud against claim_est_payout
payout_uni
payout_fraud <- train %>% 
  select(fraud, claim_est_payout) %>%
  filter(!is.na(claim_est_payout), fraud == "Fraud")
payout_fraud

payout_no_fraud <- train %>% 
  select(fraud, claim_est_payout) %>%
  filter(!is.na(claim_est_payout), fraud == "No Fraud")
payout_no_fraud

cvm_test(payout_fraud$claim_est_payout, payout_no_fraud$claim_est_payout)

ad_test(payout_fraud$claim_est_payout, payout_no_fraud$claim_est_payout)
## The distribution of claim_est_payout for fraud and claim_est_payout for no fraud are statistically significant different.

## 19. fraud against age_of_vehicle
veh_age_uni
veh_age_fraud <- train %>% 
  select(fraud, age_of_vehicle) %>%
  filter(!is.na(age_of_vehicle), fraud == "Fraud")
veh_age_fraud

veh_age_no_fraud <- train %>% 
  select(fraud, age_of_vehicle) %>%
  filter(!is.na(age_of_vehicle), fraud == "No Fraud")
veh_age_no_fraud

cvm_test(veh_age_fraud$age_of_vehicle, veh_age_no_fraud$age_of_vehicle)

ad_test(veh_age_fraud$age_of_vehicle, veh_age_no_fraud$age_of_vehicle)
## The distributions of age_of_vehicle for fraud and age_of_vehicle for no fraud are statistically significant different.

## 20. fraud against vehicle_category
category_uni
category_chi <- train %>%
  filter(!is.na(vehicle_category)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(vehicle_category) %>%
  summarize(category_total = n(),
            category_fraud = sum(fraud_numeric == 1)) %>%
  select(category_total, category_fraud)

as.matrix(category_chi)

category_matrix <- as.matrix(category_chi)
dim(category_matrix)
category_prop_chi <- chisq.test(category_matrix)
category_prop_chi
##p-value = 0.9432 (> 0.05), we fail to reject the null hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for different vehicle_categories have no difference.

## 21. fraud against LOG TRANSFORMED vehicle_price
price_uni

price_fraud <- train %>% 
  select(fraud, vehicle_price) %>%
  filter(!is.na(vehicle_price), fraud == "Fraud")
price_fraud

price_no_fraud <- train %>% 
  select(fraud, vehicle_price) %>%
  filter(!is.na(vehicle_price), fraud == "No Fraud")
price_no_fraud

cvm_test(price_fraud$vehicle_price, price_no_fraud$vehicle_price)
ad_test(price_fraud$vehicle_price, price_no_fraud$vehicle_price)
## Since the p_value are larger than 0.05.The distributions of vehicle-price for fraud and  for no fraud are not statistically significant different(no difference).

## 22. fraud against vehicle_color
color_uni
color_chi <- train %>%
  filter(!is.na(vehicle_color)) %>%
  mutate(fraud_numeric = ifelse(fraud == "Fraud", 1, 0)) %>%
  group_by(vehicle_color) %>%
  summarize(color_total = n(),
            color_fraud = sum(fraud_numeric == 1)) %>%
  select(color_total, color_fraud)

as.matrix(color_chi)

color_matrix <- as.matrix(color_chi)
dim(color_matrix)
color_prop_chi <- chisq.test(color_matrix)
color_prop_chi
##0.8187 (> 0.05), we fail to reject the null hypothesis and conclude that there is evidence to suggest that the proportions of fraud cases for different colors have no difference.

## 23. fraud against vehicle_weight
weight_uni
weight_fraud <- train %>% 
  select(fraud, vehicle_weight) %>%
  filter(!is.na(vehicle_weight), fraud == "Fraud")
weight_fraud

weight_no_fraud <- train %>% 
  select(fraud, vehicle_weight) %>%
  filter(!is.na(vehicle_weight), fraud == "No Fraud")
weight_no_fraud

cvm_test(weight_fraud$vehicle_weight, weight_no_fraud$vehicle_weight)

ad_test(weight_fraud$vehicle_weight, weight_no_fraud$vehicle_weight)

##The distributions of vehicle_weight for fraud and no fraud are statistically insignificant different (no difference).

```
As result, statistically significant predictor variables: 
age, gender, marital_status, annual_income, high_education_ind, address_change_ind, living_status, witness_present_ind, liab_prct,policy_report_filed_ind,claim_est_payout,age_of_vehicle, past_num_of_claims

```{r bivariate: correlation matrix & heatmap}


```

```{r bivariate: logistic model & visualization}

#correlated variables: (y,x)
#log_annual_income, marital_status; 
#age_of_driver vs log_annual_income;
#log_annual_income, gender;
#living_status, log_annual_income;
#log_annual_income vs past_num_of_claims;
#age_of_driver vs past_num_claims;
#policy_report_filed_ind, past_num_of_claims; 
#witness_present_ind, policy_report_filed_ind;        
#living_status, policy_report_filed_ind;
#high_education_ind vs living_status;
```

```{r ML modeling for feature importance verification}
## Random Forest
library(randomForest)

test <- read.csv("data/test_2023.csv")




## XGBoost

```


